upCI <- numeric(length(ncol(fvalues)))
for(i in 1:ncol(fvalues)){
lowCI[i] <- quantile(fvalues[,i], alpha/2, type = 1)
upCI[i] <- quantile(fvalues[,i], 1-alpha/2, type = 1)
}
mont.carloData.CF <- cbind(fval.means, lowCI, upCI, Anova(CI.m3)[["F value"]][1])
mont.carloData.CF
mont.carloData.PWC <- cbind(fval.means, lowCI, upCI, Anova(all.m3,  type = 2)[["F value"]][1])
mont.carloData.PWC
alpha <- 0.05  # for 95% confidence interval
bootstrap <- 999
new_act <- numeric(length(bootstrap))
fvalues <- matrix(nrow = 999, ncol = 1)
colnames(fvalues) <- c("Temp")
for(i in 1:bootstrap){
new_grow <- lm(sample(all.data$Per_Weight)~sample(all.data$Bucket))
fvalues[i,] <- Anova(new_grow, type = 2)[["F value"]][1]
}
fvalues <- as.data.frame(fvalues)
fval.means <- colMeans(fvalues)
lowCI <- numeric(length(ncol(fvalues)))
upCI <- numeric(length(ncol(fvalues)))
for(i in 1:ncol(fvalues)){
lowCI[i] <- quantile(fvalues[,i], alpha/2, type = 1)
upCI[i] <- quantile(fvalues[,i], 1-alpha/2, type = 1)
}
mont.carloData.PWC <- cbind(fval.means, lowCI, upCI, Anova(all.m3,  type = 2)[["F value"]][1])
mont.carloData.PWC
if(!("AICcmodavg" %in% installed.packages())){
install.packages("AICcmodavg")
}
if(!("car" %in% installed.packages())){
install.packages("car")
}
if(!("multcomp" %in% installed.packages())){
install.packages("multcomp")
}
if(!("lsmeans" %in% installed.packages())){
install.packages("lsmeans")
}
if(!("multcompView" %in% installed.packages())){
install.packages("multcompView")
}
library(AICcmodavg)
library(car)
library(multcomp)
library(lsmeans)
library(multcompView)
if(!("AICcmodavg" %in% installed.packages())){
install.packages("AICcmodavg")
}
if(!("car" %in% installed.packages())){
install.packages("car")
}
if(!("multcomp" %in% installed.packages())){
install.packages("multcomp")
}
if(!("lsmeans" %in% installed.packages())){
install.packages("lsmeans")
}
if(!("multcompView" %in% installed.packages())){
install.packages("multcompView")
}
library(AICcmodavg)
library(car)
library(multcomp)
library(lsmeans)
library(multcompView)
## Read In Data ##
mort.data <- read.csv("./data/Mortality.csv")
## Read In Data ##
mort.data <- read.csv("./data/Mortality.csv")
# round temperature data
mort.data$Treatment_Temperature <- round(mort.data$Treatment_Temperature, digits = 1)
# remove those that could not be identified to the species level
mort.data <- mort.data[!mort.data$Species == "" & !mort.data$Species == "Hybrid",]
# calculate days dead and survived
mort.data$DaysDead <- 14-mort.data$Days_Survived
mort.data$PropDaysSurv <- mort.data$Days_Survived/14
## Combine Black and Yellowtail Data ##
# Make a new species column that combines black and yellowtail rockfish
mort.data$Species2 <- NA
# Find all rows where species is either black or yellowtail and add BY to new species column
for(i in 1:nrow(mort.data)){
if(mort.data$Species[i] == "Black" | mort.data$Species[i] == "Yellowtail"){
mort.data$Species2[i] <- "BY"
} else {
mort.data$Species2[i] <- mort.data$Species[i]
}
}
# Factor new species column
mort.data$Species2 <- as.factor(mort.data$Species2)
# Set levels to meaningful names
levels(mort.data$Species2) <- c("Copper", "Quillback", "BY")
#### Combine Quillback and Copper ####
# Make a new species column that combines black and yellowtail rockfish
mort.data$Species3 <- NA
# Find all rows where species is either black or yellowtail and add BY to new species column
for(i in 1:nrow(mort.data)){
if(mort.data$Species2[i] == "Copper" | mort.data$Species2[i] == "Quillback"){
mort.data$Species3[i] <- "CQ"
} else {
mort.data$Species3[i] <- mort.data$Species2[i]
}
}
# Factor new species column
mort.data$Species3 <- as.factor(mort.data$Species3)
# Change factor level names
levels(mort.data$Species3) <- c("BY", "CQ")
################################
#### Complex Level Analysis ####
################################
### Original model - NOT USING due to overdispersion in our data ##
## Logistic regression with interaction of temp and species where complexes are combined
log.mod.all.complex <- glm(cbind(Days_Survived, DaysDead)~Treatment_Temperature*Species3,
family = binomial(link = 'logit'), data = mort.data)
summary(log.mod.all.complex)
Anova(log.mod.all.complex, type = 2)
## Use capital Anova for sums of squares that equals Type II sums of squares where
## the SS are calculated for the main effects but not the interaction and should
## only be used when there is not a significant interaction statistically more
## powerful then Type III
## Check Assumptions
# Dispersion
var(mort.data$DaysDead) # 9.71
mean(mort.data$DaysDead) # 1.72
# RESULT: Data are overdispersed
# Diagnostic plots for outliers and intercorrelation
par(mfrow = c(2,2))
plot(log.mod.all.complex)
# RESULT: variance is not equal across data points (scale-location plot) change to quasibinomial
# Autocorrelation
par(mfrow = c(1,1))
acf(log.mod.all.complex$residuals)
# RESULT: no autocorrelation
### QUASIBINOMIAL - due to overdispersion (this will produce conservative p-values if you have overdispersion)
quasi.mod.all.complex <- glm(cbind(Days_Survived, DaysDead)~Treatment_Temperature*Species3,
family = quasibinomial(link = 'logit'), data = mort.data)
summary(quasi.mod.all.complex)
Anova(quasi.mod.all.complex, type = 3)
# type 3 due to significant interaction
# Significant interaction but check likelihood ratio test to ensure best model
quasi.mod.all.complex2 <- glm(cbind(Days_Survived, DaysDead)~Treatment_Temperature+Species3,
family = quasibinomial(link = 'logit'), data = mort.data)
summary(quasi.mod.all.complex2)
Anova(quasi.mod.all.complex2, type = 2)
anova(quasi.mod.all.complex2, quasi.mod.all.complex , test = "LRT")
## RESULT: Model 1 with interaction is the best model according to LRT
###################################
#### Species in a Single Model ####
###################################
### All Four Species ##############
## Logistic regression for the interaction between temperature and species on survival
log.mod.all.prop <- glm(cbind(Days_Survived, DaysDead)~Treatment_Temperature*Species,
family = quasibinomial(link = 'logit'), data = mort.data)
summary(log.mod.all.prop)
Anova(log.mod.all.prop, type = 3)
drop1(log.mod.all.prop)
# Best Model
# Giving warning because of the Yellowtail data.
# Its because the "link" score is very large.
# We have overfit our data.
#####################
#### BY Combined ####
#####################
## Logistic regression with interaction of temp and species where BY combined
quasiModel1 <- glm(cbind(Days_Survived, DaysDead)~Treatment_Temperature*Species2,
family = quasibinomial(link = "logit"),
data = mort.data)
summary(quasiModel1)
Anova(quasiModel1, type = 2)
# Interaction is not significant check LRT
# dropping interaction term
quasiModel2 <- glm(cbind(Days_Survived, DaysDead)~Treatment_Temperature + Species2,
family = quasibinomial(link = "logit"),
data = mort.data)
Anova(quasiModel2, type = 2)
summary(quasiModel2)
anova(quasiModel1, quasiModel2,  test = "LRT")
# RESULT: Can drop the interaction term due to nonsignificant LRT
# run least-squares means to identify which species are different
multcompar <- lsmeans(quasiModel2, pairwise ~ Species2, adjust = "Tukey")
summary(multcompar)
###################################################
#### Create Prediction for Logistic Regression ####
###################################################
BY.pred <- predict(log.mod.all.complex, data.frame(Treatment_Temperature = 10:23,
Species3 = "BY"), se.fit = TRUE)
CQ.pred <- predict(log.mod.all.complex, data.frame(Treatment_Temperature = 10:23,
Species3 = "CQ"), se.fit = TRUE)
Quill.pred <- predict(quasiModel2, data.frame(Treatment_Temperature = 10:23,
Species2 = "Quillback"), se.fit = TRUE)
Copper.pred <- predict(quasiModel2, data.frame(Treatment_Temperature = 10:23,
Species2 = "Copper"), se.fit = TRUE)
##############
#### Plot ####
##############
# set the plotting window - 4 panels
par(mfrow = c(2,2))
par(oma = c(4, 4, 1, 1))
par(mar = c(2, 2, 1, 1))
############################
#### BY Complex Panel A ####
############################
plot(mort.data$PropDaysSurv[mort.data$Species == "Black"] ~
mort.data$Treatment_Temperature[mort.data$Species == "Black"],
xlim = c(10,23), col = "black", pch = 19, bty = "l",
ylim = c(0,1), xaxt = "n")
points(mort.data$PropDaysSurv[mort.data$Species == "Yellowtail"] ~
mort.data$Treatment_Temperature[mort.data$Species == "Yellowtail"],
pch = 19, col = "black")
points(y=exp(BY.pred$fit)/(1+exp(BY.pred$fit)), x = 10:23,
type = "l")
points(y = exp(BY.pred$fit+1.96*BY.pred$se.fit)/
(1+exp(BY.pred$fit+1.96*BY.pred$se.fit)),
x = 10:23, type = "l", col = "lightgrey")
points(y = exp(BY.pred$fit-1.96*BY.pred$se.fit)/
(1+exp(BY.pred$fit-1.96*BY.pred$se.fit)),
x = 10:23, type = "l", col = "lightgrey")
legend("bottomleft", legend = "BY Complex", pch = 19,
col = "black",  cex = 0.8)
mtext(text = "A", side = 3, adj = 0.01, padj = 0.01)
########################
#### Copper Panel C ####
########################
plot(PropDaysSurv[mort.data$Species=="Copper"]~
Treatment_Temperature[mort.data$Species=="Copper"],
data = mort.data, pch = 15, col = "darkorange2", yaxt = "n",
bty = "l", ylim = c(0,1), xlim = c(10,23), xaxt = "n")
points(y=exp(Copper.pred$fit)/(1+exp(Copper.pred$fit)), x = 10:23,
type = "l")
points(y = exp(Copper.pred$fit-1.96*(Copper.pred$se.fit))/
(1+exp(Copper.pred$fit-1.96*Copper.pred$se.fit)),
x = 10:23, type = "l", col = "lightgrey")
points(y = exp(Copper.pred$fit+1.96*(Copper.pred$se.fit))/
(1+exp(Copper.pred$fit+1.96*Copper.pred$se.fit)),
x = 10:23, type = "l", col = "lightgrey")
legend("bottomleft", legend = "Copper", pch = 15, col = "darkorange2", cex = 0.8)
mtext(text = "C", side = 3, adj = 0.01, padj = 0.01)
############################
#### CQ complex Panel B ####
############################
plot(mort.data$PropDaysSurv[mort.data$Species == "Copper"] ~
mort.data$Treatment_Temperature[mort.data$Species == "Copper"],
col = "orange", xlim = c(10,23), xlab = "",
pch = 19, bty = "l", ylim = c(0,1), ylab = "")
points(mort.data$PropDaysSurv[mort.data$Species == "Quillback"] ~
mort.data$Treatment_Temperature[mort.data$Species == "Quillback"],
col = "orange", pch = 19)
points(y=exp(CQ.pred$fit)/(1+exp(CQ.pred$fit)), x = 10:23,
type = "l")
points(y = exp(CQ.pred$fit+1.96*CQ.pred$se.fit)/
(1+exp(CQ.pred$fit+1.96*CQ.pred$se.fit)),
x = 10:23, type = "l", col = "lightgrey")
points(y = exp(CQ.pred$fit-1.96*CQ.pred$se.fit)/
(1+exp(CQ.pred$fit-1.96*CQ.pred$se.fit)),
x = 10:23, type = "l", col = "lightgrey")
legend("bottomleft", legend = "CQ Complex", pch = 19,
col = "orange", cex = 0.8)
mtext(text = "B", side = 3, adj = 0.01, padj = 0.01)
###########################
#### Quillback Panel D ####
###########################
plot(PropDaysSurv[mort.data$Species=="Quillback"]~
Treatment_Temperature[mort.data$Species=="Quillback"],
data = mort.data, pch = 17, col = "brown", yaxt = "n",
bty = "l", ylim = c(0,1), xlim = c(10,23), xlab = "", ylab = "")
legend("bottomleft", legend = "Quillback", pch = 17, col = "brown", cex = 0.8)
points(y=exp(Quill.pred$fit)/(1+exp(Quill.pred$fit)), x = 10:23, type = "l")
points(y = exp(Quill.pred$fit+1.96*Quill.pred$se.fit)/
(1+exp(Quill.pred$fit+1.96*Quill.pred$se.fit)),
x = 10:23, type = "l", col = "lightgrey")
points(y = exp(Quill.pred$fit-1.96*Quill.pred$se.fit)/
(1+exp(Quill.pred$fit-1.96*Quill.pred$se.fit)),
x = 10:23, type = "l", col = "lightgrey")
#points(y=qb.y, x = 10:23, type = "l")
mtext(text = "D", side = 3, adj = 0.01, padj = 0.01)
mtext("Proportion of Days Survived", side = 2, outer = TRUE, cex = 1, line = 2.2)
mtext(expression(paste('Treatment Temperature (',degree,'C)',sep='')), side = 1,
outer = TRUE, cex = 1, line = 2.2)
## Read in data ##
full.act <- read.csv("data/20171129_ActivityData.csv")
# Input data
df.growth <- read.csv("data/Fish_Measurement_Data_Final.csv")
write.csv(last.day.blk, "data/last.day.blk.csv")
write.csv(last.day.cp, "data/last.day.cp.csv")
write.csv(start.day.blk, "data/start.day.blk.csv")
write.csv(start.day.cp, "data/start.day.cp.csv")
copper.data <- read.csv("data/Copper_Weight.csv", header = TRUE)
black.data <- read.csv("data/Black_Weight.csv", header = TRUE)
# Input data
aphdailySST <- read.csv("./data/AmphitriteDailySalTemp.csv")
# Load Libraries
library(ggplot2)
library(scales)
library(dplyr)
# Input data
aphdailySST <- read.csv("./data/AmphitriteDailySalTemp.csv")
# Manipulate Data
aphdaily2004 <- subset(aphdailySST, subset = aphdailySST$Year > 2003 & aphdailySST$Year < 2016)
aphdaily2004 <- aphdaily2004[aphdaily2004$Temperature < 99.9,]
aphdaily2004$MonthDay <- paste(aphdaily2004$Month, aphdaily2004$Day)
aphdaily2004$YMD <- paste(aphdaily2004$Year, aphdaily2004$Month, aphdaily2004$Day)
aphdaily2004$Date <- as.Date(aphdaily2004$YMD, "%Y %m %d")
recruitmentMonths <- aphdaily2004[aphdaily2004$Month == 5 |
aphdaily2004$Month == 6 |
aphdaily2004$Month == 7 |
aphdaily2004$Month == 8, ]
## Import data
tempSampSitesOrg <- read.csv("./data/TempData_site_Species.csv")
## Subsetting
# for columns of interest
tempSampSitesOrg <- subset(tempSampSitesOrg, select = c(ActualDate, Site, Temperature))
# Subset for only those values over 0 (zeros added when temperatures weren't taken)
tempSampSitesNoZeros <- tempSampSitesOrg[tempSampSitesOrg$Temperature > 0,]
# Remove rows with any NAs
tempSampSites <- na.omit(tempSampSitesNoZeros)
## Data manipulation
# Convert date column to date format and extract year for new column
tempSampSites$Date <- as.Date(tempSampSites$ActualDate, "%m/%d/%Y")
tempSampSites$Year <- substring(as.character(tempSampSites$Date),1,4)
tempSampSites$Month <- as.numeric(substring(as.character(tempSampSites$Date),6,7))
# Convert number months to names
tempSampSites$MonthName <- NA
for(i in 1:nrow(tempSampSites)){
if(tempSampSites$Month[i] == 6){
tempSampSites$MonthName[i] <- "June"
} else if(tempSampSites$Month[i] == 7){
tempSampSites$MonthName[i] <- "July"
} else if(tempSampSites$Month[i] == 8){
tempSampSites$MonthName[i] <- "August"
} else if(tempSampSites$Month[i] == 5){
tempSampSites$MonthName[i] <- "May"
} else {
tempSampSites$MonthName[i] <- NA
}
}
# Convert data into the same scale some years Fahrenheit was taken others Celcius
for(i in 1:nrow(tempSampSites)){
if(tempSampSites$Temperature[i] > 40){
tempSampSites$Temperature[i] <- (tempSampSites$Temperature[i]-32)*(5/9)
} else {
tempSampSites$Temperature[i] <- tempSampSites$Temperature[i]
}
}
# Subset the data for only sites I sampled
tempSampSixSites <- tempSampSites[tempSampSites$Site == "Bluestone" |
tempSampSites$Site == "Blowhole" |
tempSampSites$Site == "Execution" |
tempSampSites$Site == "Nudibranch" |
tempSampSites$Site == "Prasiola" |
tempSampSites$Site == "Whittlestone", ]
# Set standard error function
SE <- function(x){
sd(x)/sqrt(length(x))
}
meanTempKaties <- aggregate(Temperature~Month+Year, data = tempSampSixSites, FUN = mean)
confidMeanTempKaties <- aggregate(Temperature~Month+Year, data = tempSampSixSites, FUN = SE)
meanTempKaties$upp <- meanTempKaties$Temperature + 1.96*confidMeanTempKaties$Temperature
meanTempKaties$lowr <- meanTempKaties$Temperature - 1.96*confidMeanTempKaties$Temperature
maxTempKaties <- aggregate(Temperature~Date, data = tempSampSixSites, FUN = max)
### boxplot of the two datasets ###
sites.df <- tempSampSixSites[,c(3,5,6)]
aph.df <- recruitmentMonths[,c(1:2, 5)]
sites.df$location <- "SampSites"
aph.df$location <- "Aphrodite Point"
colnames(sites.df) <- c("SST", "year", "month", "location")
colnames(aph.df) <- c("year", "month", "SST", "location")
df.locs <- rbind(sites.df, aph.df)
df.locs <- na.omit(df.locs, cols = year)
par(mfrow = c(1,1))
boxplot(SST~location+year, data = df.locs, at = c(1:2, 4:5, 7:8, 10:11, 13:14, 16:17, 19:20, 22:23, 25:26, 28:29, 31:32, 34:35), col = c("cornflowerblue", "aquamarine" ), names = c("      2004", "", "     2005", "", "      2006", "", "      2007", "", "      2008", "", "      2009", "", "      2010", "", "       2011", "", "      2012", "", "      2013", "", "      2014", "", "      2015", ""), ylab = expression(paste('Sea Surface Temperature (',degree,'C)',sep='')), xlab = "Year", las = 2)
legend("topleft", legend = c("Aphrodite Point", "Six Sampling Locations"), fill = c("cornflowerblue", "aquamarine"), cex = 0.8)
### Exploring above 16 per year ###
nrow(sites.df)
nrow(sites.df[sites.df$SST >= 16, ])
sites.df[sites.df$SST <= 16, ]
## Create a for loop to determine the proportion of days per month year combo that are above 16 C
## Get sampling day average across all sites
aveTempPerDay <- aggregate(Temperature~Date, data = tempSampSixSites, FUN = mean)
uniqueYearMonth <- unique(paste(tempSampSixSites$Year, tempSampSixSites$Month))
datesAbove <- NULL
datesBelow <- NULL
for(i in 1:length(uniqueYearMonth)){
for(j in 1:nrow(tempSampSixSites)){
if(uniqueYearMonth[i] == paste(tempSampSixSites$Year[j],
tempSampSixSites$Month[j])){
if(tempSampSixSites$Temperature[j] >= 16){
datesAbove <- c(datesAbove, as.character(tempSampSixSites$ActualDate[j]))
} else {
datesBelow <- c(datesBelow, as.character(tempSampSixSites$ActualDate[j]))
}
}
}
}
fieldTempMod<- lm(SST~location, data = df.locs)
summary(fieldTempMod)
Anova(fieldTempMod, type = 2)
shapiro.test(fieldTempMod$residuals) #0.002
plot(fieldTempMod)
qqplot(fieldTempMod$residuals)
fieldTempMod$residuals
qqnorm(fieldTempMod$residuals)
qqline(fieldTempMod$residuals)
qqline(fieldTempMod$residuals, col = "red")
# Input data
aphdailySST <- read.csv("./data/AmphitriteDailySalTemp.csv")
# Manipulate Data
aphdaily2004 <- subset(aphdailySST, subset = aphdailySST$Year > 2003 & aphdailySST$Year < 2016)
aphdaily2004 <- aphdaily2004[aphdaily2004$Temperature < 99.9,]
aphdaily2004$MonthDay <- paste(aphdaily2004$Month, aphdaily2004$Day)
aphdaily2004$YMD <- paste(aphdaily2004$Year, aphdaily2004$Month, aphdaily2004$Day)
aphdaily2004$Date <- as.Date(aphdaily2004$YMD, "%Y %m %d")
recruitmentMonths <- aphdaily2004[aphdaily2004$Month == 5 |
aphdaily2004$Month == 6 |
aphdaily2004$Month == 7 |
aphdaily2004$Month == 8, ]
## Import data
tempSampSitesOrg <- read.csv("./data/TempData_site_Species.csv")
## Subsetting
# for columns of interest
tempSampSitesOrg <- subset(tempSampSitesOrg, select = c(ActualDate, Site, Temperature))
# Subset for only those values over 0 (zeros added when temperatures weren't taken)
tempSampSitesNoZeros <- tempSampSitesOrg[tempSampSitesOrg$Temperature > 0,]
# Remove rows with any NAs
tempSampSites <- na.omit(tempSampSitesNoZeros)
## Data manipulation
# Convert date column to date format and extract year for new column
tempSampSites$Date <- as.Date(tempSampSites$ActualDate, "%m/%d/%Y")
tempSampSites$Year <- substring(as.character(tempSampSites$Date),1,4)
tempSampSites$Month <- as.numeric(substring(as.character(tempSampSites$Date),6,7))
# Convert number months to names
tempSampSites$MonthName <- NA
for(i in 1:nrow(tempSampSites)){
if(tempSampSites$Month[i] == 6){
tempSampSites$MonthName[i] <- "June"
} else if(tempSampSites$Month[i] == 7){
tempSampSites$MonthName[i] <- "July"
} else if(tempSampSites$Month[i] == 8){
tempSampSites$MonthName[i] <- "August"
} else if(tempSampSites$Month[i] == 5){
tempSampSites$MonthName[i] <- "May"
} else {
tempSampSites$MonthName[i] <- NA
}
}
# Convert data into the same scale some years Fahrenheit was taken others Celcius
for(i in 1:nrow(tempSampSites)){
if(tempSampSites$Temperature[i] > 40){
tempSampSites$Temperature[i] <- (tempSampSites$Temperature[i]-32)*(5/9)
} else {
tempSampSites$Temperature[i] <- tempSampSites$Temperature[i]
}
}
# Subset the data for only sites I sampled
tempSampSixSites <- tempSampSites[tempSampSites$Site == "Bluestone" |
tempSampSites$Site == "Blowhole" |
tempSampSites$Site == "Execution" |
tempSampSites$Site == "Nudibranch" |
tempSampSites$Site == "Prasiola" |
tempSampSites$Site == "Whittlestone", ]
# Set standard error function
SE <- function(x){
sd(x)/sqrt(length(x))
}
meanTempKaties <- aggregate(Temperature~Month+Year, data = tempSampSixSites, FUN = mean)
confidMeanTempKaties <- aggregate(Temperature~Month+Year, data = tempSampSixSites, FUN = SE)
meanTempKaties$upp <- meanTempKaties$Temperature + 1.96*confidMeanTempKaties$Temperature
meanTempKaties$lowr <- meanTempKaties$Temperature - 1.96*confidMeanTempKaties$Temperature
maxTempKaties <- aggregate(Temperature~Date, data = tempSampSixSites, FUN = max)
## Create a for loop to determine the proportion of days per month year combo that are above 16 C
## Get sampling day average across all sites
aveTempPerDay <- aggregate(Temperature~Date, data = tempSampSixSites, FUN = mean)
uniqueYearMonth <- unique(paste(tempSampSixSites$Year, tempSampSixSites$Month))
datesAbove <- NULL
datesBelow <- NULL
for(i in 1:length(uniqueYearMonth)){
for(j in 1:nrow(tempSampSixSites)){
if(uniqueYearMonth[i] == paste(tempSampSixSites$Year[j],
tempSampSixSites$Month[j])){
if(tempSampSixSites$Temperature[j] >= 16){
datesAbove <- c(datesAbove, as.character(tempSampSixSites$ActualDate[j]))
} else {
datesBelow <- c(datesBelow, as.character(tempSampSixSites$ActualDate[j]))
}
}
}
}
fieldTempMod<- lm(SST~location, data = df.locs)
sites.df <- tempSampSixSites[,c(3,5,6)]
aph.df <- recruitmentMonths[,c(1:2, 5)]
sites.df$location <- "SampSites"
aph.df$location <- "Aphrodite Point"
colnames(sites.df) <- c("SST", "year", "month", "location")
colnames(aph.df) <- c("year", "month", "SST", "location")
df.locs <- rbind(sites.df, aph.df)
df.locs <- na.omit(df.locs, cols = year)
par(mfrow = c(1,1))
boxplot(SST~location+year, data = df.locs, at = c(1:2, 4:5, 7:8, 10:11, 13:14, 16:17, 19:20, 22:23, 25:26, 28:29, 31:32, 34:35), col = c("cornflowerblue", "aquamarine" ), names = c("      2004", "", "     2005", "", "      2006", "", "      2007", "", "      2008", "", "      2009", "", "      2010", "", "       2011", "", "      2012", "", "      2013", "", "      2014", "", "      2015", ""), ylab = expression(paste('Sea Surface Temperature (',degree,'C)',sep='')), xlab = "Year", las = 2)
legend("topleft", legend = c("Aphrodite Point", "Six Sampling Locations"), fill = c("cornflowerblue", "aquamarine"), cex = 0.8)
### Exploring above 16 per year ###
nrow(sites.df)
nrow(sites.df[sites.df$SST >= 16, ])
sites.df[sites.df$SST <= 16, ]
fieldTempMod<- lm(SST~location, data = df.locs)
summary(fieldTempMod)
Anova(fieldTempMod, type = 2)
shapiro.test(fieldTempMod$residuals) #0.002
qqnorm(fieldTempMod$residuals)
qqline(fieldTempMod$residuals, col = "red")
plot(fieldTempMod)
df.locs
